{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WDC1JoxWk8C",
        "outputId": "398a653b-163f-4ce2-b92b-54ba71af8de5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K‚†ß\u001b[1G\u001b[0K\n",
            "changed 22 packages in 975ms\n",
            "\u001b[1G\u001b[0K‚†ß\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K‚†ß\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K‚†ß\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K‚†ß\u001b[1G\u001b[0K"
          ]
        }
      ],
      "source": [
        "# 1. Install necessary Python libraries\n",
        "!pip install -q streamlit opencv-python-headless tensorflow numpy pandas pillow\n",
        "\n",
        "# 2. Install Localtunnel to create the public URL\n",
        "!npm install -q -g localtunnel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit cache clear"
      ],
      "metadata": {
        "id": "toJUM4xKXGBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import os\n",
        "os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'\n",
        "import streamlit as st\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import io\n",
        "from datetime import datetime\n",
        "from PIL import Image\n",
        "from tensorflow.keras.layers import InputLayer\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "\n",
        "# --- FIX FOR POTENTIAL MODEL LOADING ISSUES ---\n",
        "class PatchedInputLayer(InputLayer):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        if 'batch_shape' in kwargs:\n",
        "            kwargs['batch_input_shape'] = kwargs.pop('batch_shape')\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "tf.keras.utils.get_custom_objects()['InputLayer'] = PatchedInputLayer\n",
        "\n",
        "# --- APP CONFIGURATION ---\n",
        "MODEL_PATH = \"efficientnetb0_facial_skin_final.h5\"\n",
        "FACE_CASCADE_PATH = \"haarcascade_frontalface_default.xml\"\n",
        "CLASS_NAMES = [\"Clear Skin\", \"Dark Spots\", \"Puffy Eyes\", \"Wrinkles\"]\n",
        "\n",
        "@st.cache_resource\n",
        "def load_assets():\n",
        "    model = load_model(MODEL_PATH, compile=False)\n",
        "    face_cascade = cv2.CascadeClassifier(FACE_CASCADE_PATH)\n",
        "    return model, face_cascade\n",
        "\n",
        "# --- PAGE SETUP ---\n",
        "st.set_page_config(page_title=\"AI Facial Skin Analyzer\", layout=\"wide\")\n",
        "\n",
        "# --- SIDEBAR & HISTORY ---\n",
        "st.sidebar.title(\"Settings & History\")\n",
        "mode = st.sidebar.radio(\"Choose Input Mode\", [\"Upload Photo\", \"Live Camera\"])\n",
        "\n",
        "if 'history' not in st.session_state:\n",
        "    st.session_state.history = []\n",
        "\n",
        "st.title(\"üß† AI Facial Skin Analyzer\")\n",
        "\n",
        "# --- LOAD MODEL ---\n",
        "if not os.path.exists(MODEL_PATH) or not os.path.exists(FACE_CASCADE_PATH):\n",
        "    st.error(\"‚ö†Ô∏è Files missing! Please upload the model and XML files to Colab.\")\n",
        "else:\n",
        "    model, face_cascade = load_assets()\n",
        "\n",
        "    img_file = None\n",
        "    if mode == \"Upload Photo\":\n",
        "        img_file = st.file_uploader(\"Upload Image\", type=[\"jpg\", \"png\", \"jpeg\"])\n",
        "    else:\n",
        "        img_file = st.camera_input(\"Take a snapshot for analysis\")\n",
        "\n",
        "    if img_file:\n",
        "        # Optimization: Immediate resizing for speed\n",
        "        image = Image.open(img_file).convert(\"RGB\")\n",
        "\n",
        "        # Downscale image to max width of 800px to reduce processing load\n",
        "        max_width = 800\n",
        "        if image.width > max_width:\n",
        "            ratio = max_width / float(image.width)\n",
        "            new_height = int(float(image.height) * float(ratio))\n",
        "            image = image.resize((max_width, new_height), Image.Resampling.LANCZOS)\n",
        "\n",
        "        img_array = np.array(image)\n",
        "        original_img = img_array.copy()\n",
        "        display_img = img_array.copy()\n",
        "        gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "        # Faster face detection parameters\n",
        "        faces = face_cascade.detectMultiScale(\n",
        "            gray,\n",
        "            scaleFactor=1.2,\n",
        "            minNeighbors=5,\n",
        "            minSize=(50, 50)\n",
        "        )\n",
        "\n",
        "        results_log = []\n",
        "\n",
        "        # Process multiple faces\n",
        "        for i, (x, y, w, h) in enumerate(faces):\n",
        "            face_roi = img_array[y:y+h, x:x+w]\n",
        "\n",
        "            # Use INTER_AREA for faster/cleaner downsampling\n",
        "            face_roi_resized = cv2.resize(face_roi, (224, 224), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "            face_roi_preprocessed = preprocess_input(face_roi_resized)\n",
        "            face_roi_batched = np.expand_dims(face_roi_preprocessed, axis=0)\n",
        "\n",
        "            # Inference\n",
        "            preds = model.predict(face_roi_batched, verbose=0)[0]\n",
        "            idx = np.argmax(preds)\n",
        "            label = CLASS_NAMES[idx]\n",
        "            prob = preds[idx]\n",
        "\n",
        "            # Drawing annotations\n",
        "            cv2.rectangle(display_img, (x, y), (x+w, y+h), (0, 255, 0), 4)\n",
        "            cv2.putText(display_img, f\"#{i+1}: {label} ({prob:.1%})\", (x, y-10),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
        "\n",
        "            results_log.append({\n",
        "                \"Face_ID\": i + 1,\n",
        "                \"Timestamp\": datetime.now().strftime(\"%H:%M:%S\"),\n",
        "                \"Condition\": label,\n",
        "                \"Confidence\": f\"{prob:.2%}\"\n",
        "            })\n",
        "\n",
        "        # Display results\n",
        "        col1, col2 = st.columns(2)\n",
        "        with col1:\n",
        "            st.subheader(\"Captured/Uploaded\")\n",
        "            st.image(original_img, use_container_width=True)\n",
        "        with col2:\n",
        "            st.subheader(\"AI Analysis\")\n",
        "            st.image(display_img, use_container_width=True)\n",
        "\n",
        "        if results_log:\n",
        "            df_results = pd.DataFrame(results_log)\n",
        "            st.divider()\n",
        "            st.subheader(\"üìã Detection Details\")\n",
        "            st.table(df_results)\n",
        "\n",
        "            st.session_state.history.extend(results_log)\n",
        "\n",
        "            # Download Actions\n",
        "            st.markdown(\"### üì• Download Results\")\n",
        "            dl_col1, dl_col2 = st.columns(2)\n",
        "\n",
        "            with dl_col1:\n",
        "                csv = df_results.to_csv(index=False).encode('utf-8')\n",
        "                st.download_button(\n",
        "                    label=\"Download Report (CSV)\",\n",
        "                    data=csv,\n",
        "                    file_name=f\"analysis_{datetime.now().strftime('%H%M%S')}.csv\",\n",
        "                    mime='text/csv',\n",
        "                )\n",
        "\n",
        "            with dl_col2:\n",
        "                result_img_pil = Image.fromarray(display_img)\n",
        "                buf = io.BytesIO()\n",
        "                result_img_pil.save(buf, format=\"JPEG\", optimize=True, quality=85)\n",
        "                st.download_button(\n",
        "                    label=\"Download Annotated Image\",\n",
        "                    data=buf.getvalue(),\n",
        "                    file_name=f\"analyzed_{datetime.now().strftime('%H%M%S')}.jpg\",\n",
        "                    mime=\"image/jpeg\",\n",
        "                )\n",
        "        else:\n",
        "            st.warning(\"No faces detected. Ensure your face is clearly visible.\")\n",
        "\n",
        "# Sidebar History Display\n",
        "if st.session_state.history:\n",
        "    st.sidebar.markdown(\"---\")\n",
        "    st.sidebar.write(\"Recent Activity:\")\n",
        "    st.sidebar.dataframe(pd.DataFrame(st.session_state.history).tail(10))\n",
        "    if st.sidebar.button(\"Clear History\"):\n",
        "        st.session_state.history = []\n",
        "        st.rerun()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7cv4SUIhj7t",
        "outputId": "1eded6c4-cd82-4d6a-9199-1be6665940fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "# 1. Get the Password for the tunnel\n",
        "print(\"STEP 1: Copy this Tunnel Password/IP:\")\n",
        "print(urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip())\n",
        "print(\"\\nSTEP 2: Click the link below (ending in .loca.lt) to open the UI in a new tab.\")\n",
        "\n",
        "# 2. Start Streamlit and Localtunnel\n",
        "!streamlit run app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BD9_IOCOXRpn",
        "outputId": "ee4e39df-087e-49bc-b934-380bdd3f7513"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "STEP 1: Copy this Tunnel Password/IP:\n",
            "34.73.19.130\n",
            "\n",
            "STEP 2: Click the link below (ending in .loca.lt) to open the UI in a new tab.\n",
            "\u001b[1G\u001b[0K‚†ô\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K‚†ß\u001b[1G\u001b[0K‚†á\u001b[1G\u001b[0K‚†è\u001b[1G\u001b[0K‚†ã\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0Kyour url is: https://violet-clouds-float.loca.lt\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.73.19.130:8501\u001b[0m\n",
            "\u001b[0m\n",
            "2026-01-02 07:12:04.962865: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2026-01-02 07:12:04.968108: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2026-01-02 07:12:04.983401: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1767337925.009708   14242 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1767337925.017786   14242 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1767337925.038764   14242 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767337925.038875   14242 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767337925.038882   14242 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767337925.038886   14242 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-02 07:12:05.045097: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2026-01-02 07:12:12.875453: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
            "2026-01-02 07:12:43.384 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2026-01-02 07:12:43.387 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2026-01-02 07:13:25.878 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2026-01-02 07:13:25.881 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2026-01-02 07:14:20.956 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2026-01-02 07:14:20.959 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2026-01-02 07:15:16.911 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2026-01-02 07:15:16.916 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2026-01-02 07:15:55.652 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2026-01-02 07:15:55.661 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2026-01-02 07:16:23.277 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2026-01-02 07:16:23.281 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2026-01-02 07:16:39.957 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2026-01-02 07:16:39.961 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2026-01-02 07:19:48.949 MediaFileHandler: Missing file 98eb69b388f9378618b2fb54ed18ced3d15eae23bfe5f492efa2e10b.jpg\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/streamlit/runtime/memory_media_file_storage.py\", line 140, in get_file\n",
            "    return self._files_by_id[file_id]\n",
            "           ~~~~~~~~~~~~~~~~~^^^^^^^^^\n",
            "KeyError: '98eb69b388f9378618b2fb54ed18ced3d15eae23bfe5f492efa2e10b'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/streamlit/web/server/media_file_handler.py\", line 95, in validate_absolute_path\n",
            "    self._storage.get_file(absolute_path)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/streamlit/runtime/memory_media_file_storage.py\", line 142, in get_file\n",
            "    raise MediaFileStorageError(\n",
            "streamlit.runtime.media_file_storage.MediaFileStorageError: Bad filename '98eb69b388f9378618b2fb54ed18ced3d15eae23bfe5f492efa2e10b.jpg'. (No media file with id '98eb69b388f9378618b2fb54ed18ced3d15eae23bfe5f492efa2e10b')\n"
          ]
        }
      ]
    }
  ]
}